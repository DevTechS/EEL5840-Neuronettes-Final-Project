{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Notebook - Ambient Sound Classification\n",
    "\n",
    "**Final Project B - EEL5840 Fall 2025**\n",
    "\n",
    "This notebook trains the final model used for ambient sound classification.\n",
    "\n",
    "**Final Model**: SVM with RBF kernel trained on 100 advanced audio features\n",
    "**Performance**: 92.13% weighted F1-score on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_advanced_audio_features(audio, sr=48000):\n",
    "    \"\"\"\n",
    "    Extract 100 advanced audio features from a 5-second audio clip.\n",
    "    \n",
    "    Features:\n",
    "    - Time-domain: RMS (2), ZCR (2)\n",
    "    - Spectral: Centroid (2), Rolloff (2), Bandwidth (2)\n",
    "    - MFCCs: 13 coefficients Ã— 4 statistics (52)\n",
    "    - Delta-MFCCs: 13 mean values (13)\n",
    "    - Chroma: 12 pitch classes (12)\n",
    "    - Spectral Contrast: 7 bands (7)\n",
    "    - Tonnetz: 6 tonal features (6)\n",
    "    \n",
    "    Total: 100 features\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    rms = librosa.feature.rms(y=audio)[0]\n",
    "    features.append(np.mean(rms))\n",
    "    features.append(np.std(rms))\n",
    "    \n",
    "    zcr = librosa.feature.zero_crossing_rate(audio)[0]\n",
    "    features.append(np.mean(zcr))\n",
    "    features.append(np.std(zcr))\n",
    "    \n",
    "    centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
    "    features.append(np.mean(centroid))\n",
    "    features.append(np.std(centroid))\n",
    "    \n",
    "    rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
    "    features.append(np.mean(rolloff))\n",
    "    features.append(np.std(rolloff))\n",
    "    \n",
    "    bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]\n",
    "    features.append(np.mean(bandwidth))\n",
    "    features.append(np.std(bandwidth))\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    for coef in mfccs:\n",
    "        features.append(np.mean(coef))\n",
    "        features.append(np.std(coef))\n",
    "        features.append(np.max(coef))\n",
    "        features.append(np.min(coef))\n",
    "    \n",
    "    delta_mfccs = librosa.feature.delta(mfccs)\n",
    "    for coef in delta_mfccs:\n",
    "        features.append(np.mean(coef))\n",
    "    \n",
    "    chroma = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
    "    for coef in chroma:\n",
    "        features.append(np.mean(coef))\n",
    "    \n",
    "    contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)\n",
    "    for coef in contrast:\n",
    "        features.append(np.mean(coef))\n",
    "    \n",
    "    tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(audio), sr=sr)\n",
    "    for coef in tonnetz:\n",
    "        features.append(np.mean(coef))\n",
    "    \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_path='training_data_projectB.npy', \n",
    "          labels_path='training_labels_projectB.npy',\n",
    "          model_save_path='final_model.pkl',\n",
    "          sample_rate=48000):\n",
    "    \"\"\"\n",
    "    Train the final SVM model on provided training data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_path : str\n",
    "        Path to training data (.npy file, shape: [n_samples_per_clip, n_clips])\n",
    "    labels_path : str\n",
    "        Path to training labels (.npy file, shape: [n_clips])\n",
    "    model_save_path : str\n",
    "        Path to save trained model (.pkl file)\n",
    "    sample_rate : int\n",
    "        Audio sample rate (default: 48000 Hz)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    model : sklearn.pipeline.Pipeline\n",
    "        Trained SVM model\n",
    "    train_f1 : float\n",
    "        Training set F1-score\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"TRAINING AMBIENT SOUND CLASSIFICATION MODEL\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\n1. Loading data...\")\n",
    "    data_training = np.load(data_path)\n",
    "    labels_training = np.load(labels_path)\n",
    "    \n",
    "    n_samples = data_training.shape[1]\n",
    "    print(f\"   Loaded {n_samples} audio clips\")\n",
    "    print(f\"   Audio shape: {data_training.shape}\")\n",
    "    \n",
    "    print(\"\\n2. Extracting features from all audio clips...\")\n",
    "    X = []\n",
    "    for i in range(n_samples):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"   Processing clip {i}/{n_samples}...\")\n",
    "        \n",
    "        audio = data_training[:, i]\n",
    "        features = extract_advanced_audio_features(audio, sample_rate)\n",
    "        X.append(features)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    t = labels_training.astype(int) - 1\n",
    "    \n",
    "    print(f\"\\n   Feature extraction complete!\")\n",
    "    print(f\"   Feature matrix shape: {X.shape}\")\n",
    "    print(f\"   Number of features per sample: {X.shape[1]}\")\n",
    "    \n",
    "    print(\"\\n3. Splitting data (80/20 train/test)...\")\n",
    "    X_train, X_test, t_train, t_test = train_test_split(\n",
    "        X, t, test_size=0.2, stratify=t, random_state=42\n",
    "    )\n",
    "    print(f\"   Training set: {X_train.shape[0]} samples\")\n",
    "    print(f\"   Test set: {X_test.shape[0]} samples\")\n",
    "    \n",
    "    print(\"\\n4. Building SVM pipeline...\")\n",
    "    svm_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', SVC(kernel='rbf', random_state=42, probability=True))\n",
    "    ])\n",
    "    \n",
    "    param_grid = {\n",
    "        'classifier__C': [1, 5, 10, 50],\n",
    "        'classifier__gamma': [0.0001, 0.0005, 0.001, 0.005]\n",
    "    }\n",
    "    \n",
    "    print(\"\\n5. Training with GridSearchCV (5-fold CV)...\")\n",
    "    print(\"   This may take several minutes...\")\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=svm_pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, t_train)\n",
    "    \n",
    "    print(f\"\\n   Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"   Best CV F1-score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    print(\"\\n6. Evaluating on test set...\")\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    y_train = best_model.predict(X_train)\n",
    "    y_test = best_model.predict(X_test)\n",
    "    \n",
    "    train_f1 = f1_score(t_train, y_train, average='weighted')\n",
    "    test_f1 = f1_score(t_test, y_test, average='weighted')\n",
    "    \n",
    "    print(f\"   Training F1-score: {train_f1:.4f}\")\n",
    "    print(f\"   Test F1-score: {test_f1:.4f}\")\n",
    "    \n",
    "    print(\"\\n7. Saving model...\")\n",
    "    with open(model_save_path, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    print(f\"   Model saved to: {model_save_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TRAINING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Final Model: SVM with C={grid_search.best_params_['classifier__C']}, \"\n",
    "          f\"gamma={grid_search.best_params_['classifier__gamma']}\")\n",
    "    print(f\"Test F1-score: {test_f1:.4f}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return best_model, train_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING AMBIENT SOUND CLASSIFICATION MODEL\n",
      "============================================================\n",
      "\n",
      "1. Loading data...\n",
      "   Loaded 1210 audio clips\n",
      "   Audio shape: (240000, 1210)\n",
      "\n",
      "2. Extracting features from all audio clips...\n",
      "   Processing clip 0/1210...\n",
      "   Processing clip 100/1210...\n",
      "   Processing clip 200/1210...\n",
      "   Processing clip 300/1210...\n",
      "   Processing clip 400/1210...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/colemadden/miniconda3/envs/tfenv/lib/python3.12/site-packages/librosa/core/pitch.py:103: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Processing clip 500/1210...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model, train_f1 = train(\n",
    "        data_path='training_data_projectB.npy',\n",
    "        labels_path='training_labels_projectB.npy',\n",
    "        model_save_path='final_model.pkl',\n",
    "        sample_rate=48000\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
